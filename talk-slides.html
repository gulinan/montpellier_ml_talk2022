<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Cross-validation: What does it estimate and how well does it?</title>
    <meta charset="utf-8" />
    <meta name="author" content="Gül İnan  " />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <script src="libs/fabric-4.3.1/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble-0.0.1/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble-0.0.1/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#1A292C"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <link rel="stylesheet" href="cal.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# <b>Cross-validation: What does it estimate and how well does it?</b>
## by Stephen Bates, Trevor Hastie, and Robert Tibshirani <br>
### Gül İnan <br>
### <br>Istanbul Technical University
### <br><i>Machine Learning in Montpellier, Theory &amp; Practice, <br> November 25th, 2021 </i>

---







# Motivation
&lt;br&gt;
- In machine learning, when deploying a &lt;b&gt;&lt;span style="color:#067373;"&gt;predictive model&lt;/span&gt;&lt;/b&gt;, the interest is in understanding its &lt;b&gt;&lt;span style="color:#067373;"&gt;prediction accuracy&lt;/span&gt;&lt;/b&gt; on future test points. 
- The standard measure of accuracy for a predictive model is the &lt;b&gt;&lt;span style="color:#067373;"&gt;prediction error&lt;/span&gt;&lt;/b&gt;, i.e., the &lt;b&gt;&lt;span style="color:#067373;"&gt;expected loss on future points&lt;/span&gt;&lt;/b&gt;.
- Both &lt;b&gt;&lt;span style="color:#067373;"&gt;good point estimates&lt;/span&gt;&lt;/b&gt; and &lt;b&gt;&lt;span style="color:#067373;"&gt;accurate confidence intervals&lt;/span&gt;&lt;/b&gt; for prediction error are essential.
---

# Aim



---
# Setting and notation
&lt;br&gt;
- Consider a &lt;b&gt;&lt;span style="color:#067373;"&gt;supervised learning &lt;/span&gt;&lt;/b&gt; setting.  
- We have &lt;b&gt;&lt;span style="color:#067373;"&gt;features&lt;/span&gt;&lt;/b&gt; `\(X=(X_1, \ldots, X_i, \ldots X_n)  \in \mathcal{X}^{n}\)` with each `\(X_i \in \mathbb{R}^{p}\)`
and &lt;b&gt;&lt;span style="color:#067373;"&gt;responses&lt;/span&gt;&lt;/b&gt; `\(Y=(Y_1, \ldots, Y_i, \ldots, Y_n)  \in \mathcal{Y}^{n}\)`.
- We assume that the &lt;b&gt;&lt;span style="color:#067373;"&gt;data points&lt;/span&gt;&lt;/b&gt; `\((X_i,Y_i)\)` for `\(i=1,\ldots,n\)`
are i.i.d. from a &lt;b&gt;&lt;span style="color:#067373;"&gt; distribution&lt;/span&gt;&lt;/b&gt; `\(P\)`. 

---
# Setting and notation continu'ed
&lt;br&gt;
- Consider a &lt;b&gt;&lt;span style="color:#067373;"&gt;class of models parameterized&lt;/span&gt;&lt;/b&gt; by `\(\theta\)`.
- We let `\(f(X, \theta)\)` be the &lt;b&gt;&lt;span style="color:#067373;"&gt;function that predicts&lt;/span&gt;&lt;/b&gt; `\(y\)` from `\(x \in \mathbb{R}^{p}\)`, where `\(\theta\)` takes values in some space `\(\Theta\)`.
- We let `\(\mathcal{A}\)` be a &lt;b&gt;&lt;span style="color:#067373;"&gt;model-fitting algorithm&lt;/span&gt;&lt;/b&gt; that takes data points and returns a parameter vector `\(\theta \in \Theta\)` and `\(\hat \theta =\mathcal{A}(X,Y)\)` be the &lt;b&gt;&lt;span style="color:#067373;"fitted value of the parameter&lt;/span&gt;&lt;/b&gt; based on the observed data `\(X\)` and `\(Y\)`. 

---
# Prediction error 
&lt;br&gt;
- In &lt;b&gt;&lt;span style="color:#067373;"&gt;measuring accuracy of a model&lt;/span&gt;&lt;/b&gt;, we are interested in &lt;b&gt;&lt;span style="color:#067373;"&gt;out-of-sample error&lt;/span&gt;&lt;/b&gt; which is defined as the &lt;b&gt;&lt;span style="color:#067373;"&gt;expected loss&lt;/span&gt;&lt;/b&gt;:

`\begin{equation}
Err_{XY}: = \mathbb{E}\big[	\ell (\hat{f}(X_{n+1},\hat \theta ),Y_{n+1}) \vert (X,Y) \big] , \nonumber
\end{equation}`

- where `\((X_{n+1},Y_{n+1})\)` is an &lt;b&gt;&lt;span style="color:#067373;"&gt;independent test point&lt;/span&gt;&lt;/b&gt; from the same distribution `\(P\)`. 
- The expression `\(\hat{f}(X_{n+1},\hat \theta)\)` is the &lt;b&gt;&lt;span style="color:#067373;"&gt;predicted value of `\(Y_{n+1}\)`&lt;/span&gt;&lt;/b&gt; at the future point `\(X_{n+1}\)` and `\(\hat \theta\)` which is estimated through algorithm `\(\mathcal{A}\)` based on the training data `\((X,Y)\)`.
- The expression `\(\ell (\hat{f}(X_{n+1},\hat \theta ),Y_{n+1})\)` is the &lt;b&gt;&lt;span style="color:#067373;"&gt;loss&lt;/span&gt;&lt;/b&gt; between predicted value of `\(Y_{n+1}\)` and `\(Y_{n+1}\)` itself.
- Here, the &lt;b&gt;&lt;span style="color:#067373;"&gt;loss function&lt;/span&gt;&lt;/b&gt; `\(\ell(.)\)` could be squared error loss, classification error, or deviance (cross-entropy). 
- Furthermore `\(Err_{XY}\)` can be considered as a &lt;b&gt;&lt;span style="color:#067373;"&gt;random quantity&lt;/span&gt;&lt;/b&gt;  depending on the training data `\((X,Y)\)`.

---
# Expected prediction error
&lt;br&gt;
- In designing and comparing &lt;b&gt;&lt;span style="color:#067373;"&gt;learning algorithms&lt;/span&gt;&lt;/b&gt; themselves, we are interested in their &lt;b&gt;&lt;span style="color:#067373;"&gt;average performance on predicting future test points&lt;/span&gt;&lt;/b&gt;.
- We can formally define it as
the &lt;b&gt;&lt;span style="color:#067373;"&gt;expected value of prediction error when training over possible data sets of size n drawn from the same the data distribution `\(P\)`&lt;/span&gt;&lt;/b&gt;:

`\begin{equation}
Err :=\mathbb{E}\big[Err_{XY}\big].\nonumber
\end{equation}`

---

- Note that when the **data distribution** `\(P\)` is **unknown**, estimates of the quantities `\(Err_{XY}\)` and `\(Err\)` cannot be computed.
- Then, the quantities `\(Err_{XY}\)` and `\(Err\)` can be estimated through **resampling based methods** such as Cross-validation, Boostrap, and Jacknife or **analytical methods** such as AIC, BIC, Mallow's `\(C_p\)`, and covariance penalties.


---
# K-fold cross-validation
&lt;br&gt;
- In &lt;b&gt;&lt;span style="color:#067373;"&gt;K-fold cross-validation&lt;/span&gt;&lt;/b&gt;, we partition the data into equally sized &lt;b&gt;&lt;span style="color:#067373;"&gt;disjoint
subsets (folds) &lt;/span&gt;&lt;/b&gt; `\(\mathcal{I}_j\)` of size `\(m=n/K\)` at &lt;b&gt;&lt;span style="color:#067373;"&gt;random&lt;/span&gt;&lt;/b&gt; ( `\(k=1,\ldots,K\)` ).
- We also write `\({i} \in \mathcal{I}_k\)` for `\((x_i,y_i) \in \mathcal{I}_k\)`.

&lt;img src="imgs/K_CV_single.png" width="15%" style="display: block; margin: auto;" /&gt;

&lt;div style="text-align:right;"&gt;&lt;font size="4px"&gt;&lt;a href="https://www.researchgate.net/profile/Mingchao-Li/publication/331209203/figure/fig2/AS:728070977748994@1550597056956/K-fold-cross-validation-method.png"&gt;Image Source&lt;/a&gt;&lt;/font&gt;&lt;/div&gt;

---

- Consider the first fold and hold it out as future data set (or &lt;b&gt;&lt;span style="color:#067373;"&gt;test set&lt;/span&gt;&lt;/b&gt;).
- Let `\(\hat \theta^{(-1)} = \mathcal{A}(X_i,Y_i)_{i \in \mathcal{I} \backslash \mathcal{I}_{1}}\)`  be the model fit to only those points that are not in the first fold (remaining sets are called as &lt;b&gt;&lt;span style="color:#067373;"&gt;training set&lt;/span&gt;&lt;/b&gt;). 
- We calculate the prediction error of the model over fixed `\(\mathcal{I}_{1}\)` set as follows:

`\begin{equation}
 \frac{1}{m} \sum_{{i} \in \mathcal{I}_1}\ell \big(\hat{f}(x_{i},\hat \theta^{(-1) } ),y_i\big).
\end{equation}`
---
- In &lt;b&gt;&lt;span style="color:#067373;"&gt;K-fold cross-validation&lt;/span&gt;&lt;/b&gt;, we repeat this process for each fold ( `\(k=1,\ldots,K\)` ).


&lt;img src="imgs/K_CV.png" width="60%" style="display: block; margin: auto;" /&gt;

&lt;div style="text-align:right;"&gt;&lt;font size="4px"&gt;&lt;a href="https://www.researchgate.net/profile/Mingchao-Li/publication/331209203/figure/fig2/AS:728070977748994@1550597056956/K-fold-cross-validation-method.png"&gt;Image Source&lt;/a&gt;&lt;/font&gt;&lt;/div&gt;

---
# CV estimate of prediction error
&lt;br&gt;
- The &lt;b&gt;&lt;span style="color:#067373;"&gt;CV estimate of prediction error&lt;/span&gt;&lt;/b&gt; is the average of errors over K folds, given as follows:

`\begin{equation}
	\widehat {Err} ^{(CV)}:= \frac{1} {K} \sum_{k=1}^{K} \frac{1} {m}\sum_{{i} \in \mathcal{I}_k} \ell \big(\hat{f}(x_{i},\hat \theta^{(-1) } ),y_i\big).
\end{equation}`

- Intuitively, the inner sum is an estimate for `\(Err_{XY}\)` for a fixed fold, and the outer sum estimates `\(Err\)` with `\(\mathcal{I}_k\)`  ( `\(k=1,\ldots,K\)` ) being different folds from the same data set.
---
- Let 
`\(e_i =\ell \big(\hat{f}(x_{i},\hat \theta^{(-1) } ),y_i\big)\)` for each `\(i \in \mathcal{I}_k\)` ( `\(k=1,\ldots,K\)` ), and the errors `\(e_i\)` for points in other folds are defined
similarly.
- Since `\(n =  K \times m\)`,  we can **re-define** &lt;b&gt;&lt;span style="color:#067373;"&gt;CV estimate of prediction error&lt;/span&gt;&lt;/b&gt; as follows:

`\begin{equation}
	\widehat {Err } ^{(CV)}:= 	\bar e = \frac{1} {n}  \sum_{i=1}^{n}e_i. \nonumber
\end{equation}`

- An &lt;b&gt;&lt;span style="color:#067373;"&gt;estimate of the standard error of the prediction error&lt;/span&gt;&lt;/b&gt; would be:

`\begin{equation}
	\widehat{se}:=\frac{1} {\sqrt n} \times \sqrt {\frac{1} {n-1} \sum_{i=1}^{n}(e_i-\bar e)^2},  \nonumber
\end{equation}`
- where the second term in the multiplication refers to the  &lt;b&gt;&lt;span style="color:#067373;"&gt;empirical standard deviation of the `\(e_i\)`&lt;/span&gt;&lt;/b&gt;. 
---
# A `\(100(1-\alpha)\%\)` confidence interval for prediction error
&lt;br&gt;
- A `\(100(1-\alpha)\%\)` &lt;b&gt;&lt;span style="color:#067373;"&gt;confidence interval for prediction error&lt;/span&gt;&lt;/b&gt; can be constructed as follows:

`\begin{equation}
\big(\bar e - z_{1-(\frac{\alpha}{2})} \times \widehat{se} \quad, \quad \bar e + z_{1-(\frac{\alpha}{2})} \times \widehat{se}\big)
\end{equation}`

- where `\(z_{1- (\frac{\alpha}{2}) }\)` is the `\(1- (\frac{\alpha}{2})\)` quantile of the standard normal distribution. 
- The intervals are called as &lt;b&gt;&lt;span style="color:#067373;"&gt;naive cross-validation intervals&lt;/span&gt;&lt;/b&gt;.
---
# What prediction error are we estimating?
&lt;br&gt;
- `\(Err_{XY}\)` is the error of the model that was fit on the training set.
- `\(Err\)` is the average of the fitting algorithm run on the same-sized data sets drawn
from the underlying distribution `\(P\)`.
- The former quantity is of the most interest to a practitioner deploying a specific mode, whereas the latter  may be of interest to a researcher comparing different fitting algorithms.
---

&lt;img src="imgs/paper_fig2.png" width="60%" style="display: block; margin: auto;" /&gt;


---
class: center, middle

&lt;br&gt; Merci!.. &lt;/br&gt;


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "atelier-forest-light",
"highlightLines": true,
"highlightSpans": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
